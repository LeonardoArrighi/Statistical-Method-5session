---
title: "SMDS Homework - Block 5"
author: "E. Fabrici, V. Plesco, L. Arrighi | Group 'D'"
date: "22th June 2020"
output:
  html_document:
    toc: yes
  beamer_presentation:
    highlight: tango
  include: null
  ioslides_presentation:
    highlight: tango
  pdf_document:
    highlight: tango
    keep_tex: yes
    toc: yes
  slide_level: 2
  slidy_presentation:
    fig.height: 3
    fig.width: 4
    highlight: tango
header-includes:
- \usepackage{color}
- \usepackage{graphicx}
- \usepackage{grffile}
- \definecolor{Purple}{HTML}{911146}
- \definecolor{Orange}{HTML}{CF4A30}
- \setbeamercolor{alerted text}{fg=Orange}
- \setbeamercolor{frametitle}{bg=Purple}
institute: University of Trieste, SISSA, ICTP, University of Udine
graphics: yes
fontsize: 10pt
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', warning=FALSE, message=FALSE, fig.asp=0.625, dev='png', global.par = TRUE, dev.args=list(pointsize=10), fig.path = 'figs/')
library(MASS)
```

```{r setup, include=FALSE}
library(knitr)
local({
  hook_plot = knit_hooks$get('plot')
  knit_hooks$set(plot = function(x, options) {
    paste0('\n\n----\n\n', hook_plot(x, options))
  })
})
```

# Homeworks {.tabset}

## Used libraries {.tabset}

```{r}
library(ggplot2)
library(lattice)
library(DAAG)
```



## DAAG EXERCISES {.tabset}

### Chapter 7 {.tabset}

#### Exercise 2

Use `anova()` to compare the two models:
```
roller.lm <- lm(depression~weight, data=roller)
roller.lm2 <- lm(depression~weight+I(weight^2), data=roller)
```
Is there any justification for including the squared term?

##### Solution

```{r}
roller.lm <- lm(depression~weight, data=roller)
roller.lm2 <- lm(depression~weight+I(weight^2), data=roller)
anova(roller.lm, roller.lm2) #P-f test- very high
```


##### Observations

From the $F$ test it is possible to notice that the probability $Pr(F\geq f_{obs})$ is quite high, assuming the null hypothesis $H_0:\beta_{weight^2} = 0$ is true. Thus, as there is no significant difference between the two models we can keep the simpler one, namely `roller.lm`. However let's see the diagnostic plots.

```{r}
par(mfrow=c(2,2))
plot(roller.lm)
par(mfrow=c(2,2))
plot(roller.lm2)
```
In both models it is possible to observe that there is a problematic observation, the one labeled with 10, 5 and 7. The plots `Residuals vs Leverage`, `Scale-Location` and `Normal Q-Q` show clearly that the aforementioned points are suspect. Let's remove it and refit the models.
```{r}
remove <- c("5", "7", "10")
roller_mod <- roller[!rownames(roller) %in% remove,]
roller.lm <- lm(depression~weight, data=roller_mod)
roller.lm2 <- lm(depression~weight+I(weight^2), data=roller_mod)
anova(roller.lm, roller.lm2)
```
Now the p-value is even higher than before. This means that the points analysed were not problematic in terms of comparison of the two models.
##### Conclusion

We confirm our initial choice, namely there is no statistical reason to prefer one model to the other.

### Chapter 4 {.tabset}

#### Exercise 11
The table UCBAdmissions was discussed in Subsection 2.2.1. The following gives a table
that adds the 2 × 2 tables of admission data over all departments:
` ## UCBAdmissions is in the datasets package For each combination of margins 1 and 2, calculate the sumUCBtotal <- apply(UCBAdmissions, c(1,2), sum)`


##### Solution

```{r}
UCBAdmissions <- UCBAdmissions
UCBAdmissions
sumUCBtotal <- apply(UCBAdmissions, c(1,2), sum)
sumUCBtotal
```
What are the names of the two dimensions of this table?
They are *Gender* and *Admit*.

(a) From the table `UCBAdmissions`, create mosaic plots for each faculty separately. (If
necessary refer to the code given in the help page for `UCBAdmissions`.)

```{r}
# (a)
faculties <- c('A', 'B', 'C', 'D', 'E', 'F')
for (faculty in faculties) {
    mosaicplot(UCBAdmissions[,,faculty], main = paste("Faculty", faculty))
}
```

(b) Compare the information in the table `UCBtotal` with the result from applying the
function `mantelhaen.test()` to the table `UCBAdmissions`. Compare the two
sets of results, and comment on the difference.
```{r}
#(b)
mantelhaen.test(UCBAdmissions)
sumUCBtotal
```
The Mantel-Haenszel test is an inferential test for the association between two binary variables, while controlling for a third confounding nominal variable. Essentially, the test examines the weighted association of a set of $2 × 2$ tables.
In our case, we check if there is an association between the *Gender* and *Admit* over the different departments.
The null-hypothesis states that there is no association between the two variables and it is possible to observe that the p-values is equal to $0.2323$, thus the test is not statistically significant and we accept $H_0$.
The table `sumUCBtotal` it is possible to observe that there are more admitted males that females but also more rejected males than females.


The Mantel–Haenzel test is valid only if the male-to-female odds ratio for admission is
similar across departments. The following code calculates the relevant odds ratios:
`apply(UCBAdmissions, 3, function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1]))`
Is the odds ratio consistent across departments? Which department(s) stand(s) out as
different? What is the nature of the difference?

```{r}
#(c)
apply(UCBAdmissions, 3,
      function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1])
      )
```
The odds ration is not consistent across the departments. In particular, department A has a very low odds ratio compared to the others. The nature of this difference can be observed in the mosaic plots showed above, where it is possible to notice that the number of females is significantly lower than the number of males. (Also department B has this problem.)

#### Exercise x

Text here.



##### Observations

Observations.

##### Conclusion

Conclusions.



## CASI EXERCISES {.tabset}

### Chapter x {.tabset}

#### Exercise x

Text here.

##### Solution

```{r Test_ex, code = readLines("src/Test_ex.R"), echo=TRUE}
```

##### Observations

Observations.

##### Conclusion

Conclusions.



## CS EXERCISES {.tabset}

### Chapter 1 {.tabset}

#### Exercise 7

Let $Y_1$, $Y_2$ and $Y_3$ be independent $N(\mu,\sigma^2)$ r.v.s. Somehow using the matrix
$$
A=\left[\begin{array}{cc} 
1/3 & 1/3 & 1/3\\
2/3 & -1/3 & -1/3 \\
-1/3 & 2/3 & -1/3
\end{array}\right]
$$
show that
$$
\bar{Y}=\sum_{i=1}^3 Y_i /3
$$
and
$$
Z=\sum_{i=1}^3 (Y_i - \bar{Y})^2
$$
are independent random variables.

##### Solution

Due to the fact that $Y_1$, $Y_2$ and $Y_3$ are independent and distributed as $N(\mu,\sigma^2)$:
$$
\bar{Y}\sim N\left(\mu,\frac{\sigma^2}{n}\right).
$$
Due to the fact that $Z$ is a function of $Y_1$, $Y_2$ and $Y_3$, only, it is independent to $\bar{Y}$.
Hence, calling $Y=(Y_1,Y_2,Y_3)$, we can notice that, from the definition of scalar product:
$$
A\cdot Y = \begin{cases} \bar Y \\ 
Y_1 - \bar{Y}\\
Y_2 - \bar{Y}
\end{cases}
$$
Observing that the sum of two independent normal random variables has a normal distribution, we can conclude that $Y_1 - \bar{Y}$ and $Y_2 - \bar{Y}$ have a normal distribution and, similarly, we can obtain the same result for $Y_3 - \bar{Y}$). 
More specifically, for $j=1,2,3$:
$$
\begin{align}
Y_j - \bar{Y} &= \frac{2}{3} Y_j - \frac{1}{3}\sum_{i\neq j} Y_i \\
&\sim N\left(\frac{2\,\mu}{3}-\frac{2\,\mu}{3}, \, 4\cdot\frac{\sigma^2}{9}+2\cdot\frac{\sigma^2}{9}\right)\\
&=N\left( 0,\, \frac{2}{3}\,\sigma^2\right) .
\end{align}
$$
Hence, for $j=1,2,3$ we have:
$$
\begin{align}
Cov(Y_j-\bar{Y},\bar{Y}) &= Cov(Y_j,\bar{Y})-Cov(\bar{Y},\bar{Y})\\
&= \frac{\sigma^2}{3} - \frac{\sigma^2}{3} \\ &= 0. 
\end{align}
$$
Then, we can conclude that $\bar{Y}$ and $\hat{Y}=(Y_1-\bar{Y},Y_2-\bar{Y},Y_3-\bar{Y})$ are independent normal vectors, and so $\bar{Y}$ is independent of $\hat{Y}^T \hat{Y} = n Z$.